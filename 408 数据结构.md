[TOC]

> 前言：
>
> 1. 数据结构的学习**不应该纠结于算法的实现，而应该纠结于原理和如何使用**！这给我们带来的启示是，数据结构的学习在概念完毕后，更多的是熟练度，而**熟练度的增加往往需要多做题**。简而言之，数据结构**理当看一章节做一章节的题目**，这样才能做到理论和实践的迅速统一。
> 2. **遇事不决，可问 ai**
> 3. 

## 绪论

### 数据结构在学什么

个人认为，数据结构我可以简单的认为是**数据和对数据的操作**。

在学习数据结构后的编程中，应当**习惯性创建类/文件**，其实更简单的来说，就是**习惯性找一个空间，将数据和与其关联的操作等放在一块**。通过持续锻炼，养成这种习惯的过程中，可以提高自己的抽象能力和面向对象思想！



### 数据结构的基本概念

#### 数据结构的三要素

- 逻辑结构

  - 集合结构，各个元素同属一个集合，别无其他关系
  - 线性结构，一对一，顺序关系
  - 树状结构，一对多
  - 图状结构，多对多

- **数据的运算**

  针对某种逻辑结构，结合实际需求，定义基本运算（增删改查）

  > 注意这个**定义基本运算**，这个需要抽象能力。
  >
  > 举个例子：Linux 对设备的操作，其实就是收发消息，而对文件的基本操作是读和写，那么对设备的操作自然可以抽象成对文件的操作！

  - 运算的定义是针对逻辑结构的，指出运算的功能

  - 运算的实现是针对存储结构的，指出运算的具体步骤

- 物理结构（储存结构）

  - 顺序存储：把逻辑上相邻的元素存储在物理位置上也相邻的储存单元中，元素之间的关系由储存单元的邻接关系来体现
  - 链式存储：把逻辑上相邻的元素存储在物理位置上可以不相邻，借助指示元素存储地址的指针来表示元素之间的逻辑关系。
  - 索引存储：在储存元素信息的同时，还简历附加的索引表。索引表中的每项成为索引项，索引项的一般形式是（关键字，地址）
  - 散列存储：根据元素的关键字直接计算出该元素的存储地址，又称哈希存储



###  算法的基本概念

#### 什么是算法

- 程序 = 数据结构 + 算法
- 算法（Algorithm）是对特定问题求解步骤的一种描述，它是指令的有限序列，其中的每条指令表示一个或多个操作

#### 好算法的特质

- 正确性：算法应能够正确地解决求解问题。
- 可读性：算法应具有良好的可读性，以帮助人们理解。
- **健壮性**：输入非法数据时，算法能适当地做出反应或进行处理，**而不会产生莫名其妙的输出结果**。
- 高效率：
  - 花的时间少：时间复杂度低
  - 低存储量需求：不费内存，空间复杂度低



###  算法的时间复杂度

**规则：**

- 加法规则：`T(n) = T1(n) + T2(n) = O(f(n)) + O(g(n)) = O(max(f(n), g(n)))` （多项相加，只保留最高阶的项，且系数变为1）
- 乘法规则：`T(n) = T1(n)×T2(n) = O(f(n))×O(g(n)) = O(f(n)×g(n))`（多项相乘，都保留 ）
- 算法好坏：`O(1) < O(log2n) < O(n) < O(nlog2n) < O(n^2) < O(n^3) < O(2^n) < O(n!) < O(n^n)`（口诀：常对幂指阶）
- 数量级仅需考虑循环内，最深层嵌套的部分
- 最坏时间复杂度：最坏情况下算法的时间复杂度
- 平均时间复杂度：所有输入示例等概率出现的情况下，算法的期望运行时间
- 最好时间复杂度：最好情况下算法的时间复杂度
- 一般只考虑最坏和平均复杂度



### 算法的空间复杂度

**算法原地工作：** 算法所需内存空间为常量

**规则：**

- 只需关注存储空间大小与问题规模相关的变量
- 加法规则、乘法规则、算法好坏判定与时间复杂度一样
- 递归调用的大多数情况：空间复杂度=递归调用的深度



---

## 线性表
### 基础操作总结

1. 将数组的 `[left, right]` 数据平移。平移的过程中直接覆盖，超出索引的内容直接丢弃。

   - 数组插入数据和删除数据时能够使用

2. 找到链表的第 i 个节点及其前驱节点

   - 链表删除操作能够使用

   ```python
   @dataclass
   class FindNodeRet:
       pre: LNode
       node: LNode
   
   
   def find_node(pos) -> FindNodeRet:
       pre, node
       return FindNodeRet(pre=pre, node=node)
   ```

   

3. 指定结点的前插和后插操作

4. 



### 特殊矩阵的压缩储存

#### 三对角矩阵的压缩存储

此处可以帮助联想到分段函数的思想。先将特例拿出来，得到通用公式后，检查特例是否在其中，不在则形成分段函数！



---

## 树

### 线索二叉树的概念

> [!NOTE]
>
> 由于先序遍历先遍历根结点然后再遍历左结点，若左孩子为空，通过线索化后会指回前驱结点（根结点），这时再次访问左孩子时，会又访问回根结点。因此先序线索二叉树需要一些额外处理：增加一个判断来确定左孩子是真正的左孩子还是线索化后的前驱结点。如果真的是左孩子，才继续递归。
>
> 中序线索二叉树和后序线索二叉树实现起来差不多

从线索二叉树的构建过程中，体会到 | visit, dfs, dfs | dfs, visit, dfs | dfs, dfs, visit | 的模板可以做到很多事情，虽然无法传参，但是可以有全局共享变量啊，哪怕担心全局共享变量容易出问题，还可以用函数对象的方式呀！

函数对象：

```python
def create_thread_tree(*args, **kwargs):
    ...

class CreateThreadTree: 
    def __init__(self, *args, **kwargs):
        ...
    
    def call(self):
        ...
        
# 更有甚者
class create_thread_tree: # NOQA
    def __init__(self, *args, **kwargs):
        ...
        self._call()
        
    def _call(self):
        ...
```

若想让函数对象的属性等价于全局变量，让函数对象为单例即可。







### 在线索二叉树中找前驱后驱

线索二叉树构建完毕后，可以利用线索二叉树实现非递归版本的二叉树的先序/中序/后序遍历。

除此之外，还可以通过 lchild 实现逆向遍历！（中序遍历必定可以，先序和后序未验证，不确定）
以中序遍历为例：
从 root 的最右下节点开始，利用 lchild 或者 preNode 函数，往前遍历。

> [!CAUTION]
>
> 在先序线索二叉树中找到指定结点 *p 的先序前驱 pre 有些小问题，如果 p->ltag == 0，由于先序遍历是根左右，因此左右子树只可能是根的后继，所以得特别处理：1. 使用原始方法，从头遍历 2. 使用三叉链表数据结构以找到父节点。
>
> 在后序遍历中，左右子树中的结点只可能是根的前驱，不可能是后继。因此，同上述内容，在后序线索二叉树中找到指定结点 *p 的后序后继 next 有些小问题，同样需要特殊处理。



### **树的储存结构**

#### 孩子表示法（顺序+链式存储）

用数组存储各个节点

节点结构为：| data | \*firstChild |（按照我的理解，\*firstChild 可以使用 set/list 代替）



#### 孩子兄弟表示法（链式存储）

规则：

- 左指针指向**自己的**第一个孩子
- 右指针指向**自己的**第一个兄弟





### 并查集

**用数组存储各个元素**。注意需要预先创建元素和数组索引的映射关系，实际上反倒是这个映射存储了实际元素。

数组中存储该元素的父元素（实际上就是**树的双亲表示法**，里面的值就是自己对应根结点的下标）

举个例子：

| 数据元素 |  A   |  B   |  C   |  D   |  E   |  F   |  G   |  H   |  I   |  J   |  K   |
| :------: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: | :--: |
| 数组下标 |  0   |  1   |  2   |  3   |  4   |  5   |  6   |  7   |  8   |  9   |  10  |
|   S[]    |  -1  |  -1  |  -1  |  -1  |  -1  |  -1  |  -1  |  -1  |  -1  |  -1  |  -1  |



#### 并

- 定义：将两个集合合并为一个

- 实现：设集合的父节点索引分别为 A 和 B，S[A] = B 即可，等价于 A -> B

  ```mermaid
  graph TB
      %% 需要注意的是，该图的箭头反过来才是并查集表达的，但是反过来 mermaid 图形相对位置就变了。。
      A --> B
      
      subgraph S1
          A --> A1
          A --> A2
          A --> A3
      end
      style S1 fill:#ccf,stroke:#f66,stroke-width:2px,stroke-dasharray: 5, 5
      
      subgraph S2
          B --> B1
          B --> B2
          B --> B3
          B1 --> B11
          B1 --> B12
      end
      style S2 fill:#ccf,stroke:#f66,stroke-width:2px,stroke-dasharray: 5, 5
      
  
  ```

- 优化：为了尽量让树不要长高，可以让矮树指向高树







#### 查

- 定义：找到元素 X 所属的集合

- 实现：根据映射关系得到元素 X 的索引为 ix

  ```python
  def find(S, ix: int):
      while(S[ix] >= 0): # 循环寻找 x 的根
          ix = S[ix]
      return ix
  ```



#### 并查集的压缩路径

核心想法就是让树越来越“矮”

**实现：**

优化 find 操作，第一次遍历，找到元素所在的集合的根节点。第二次遍历，每次让路径上的节点指向根节点。



---

## 图

### 最短路径问题之 Dijkstra 算法

**时间复杂度：**

- O(|V|^2)

**如何理解：**

首先脑子里想象一张带权有向图，任选一个源点，为了方便理解，就选第一个顶点 A，记为 u

顶点：

- V = { A, B, C, D, E, F, G }

辅助空间：

- S = { A }，顶点在集合 S 中代表 u 到 Si 的最短路径已经找到
- dist[]，dist[i] 指当前情况下 u 到 Vi 的最短路径的值
- pre[]，用于还原具体路径，不是重点，是附加内容，目前暂不必考虑

实现思路：

- 第一轮，S = { A }，从 A 出发，根据 A 到其邻居顶点的距离更新 dist 数组

- 第二轮，从 dist 数组中找到距离最短且 Vi ∉ S 的顶点，假设是 C，更新 S = { A, C }。从 C 出发，重复第一轮的操作

- ...

- 遍历 |V| 轮后，得到最终结果。dist 数组存储 u 距离各个顶点的最短路径。

动态演示：

- [见链接](https://www.cnblogs.com/MarisaMagic/p/16927254.html)

> 文字难以描述，未来如果发现上面的内容不够直观，查看链接里的图片即可。 Dijkstra 算法和最小生成树的两个算法一样，找个实例就很好理解了，考试并不要求代码实现，只要能手算 + 记住复杂度即可。



### 最短路径问题之 Floyd 算法

> - 时间复杂度 O(n^3)
>
> - 通常用于求带权图中各顶点间的最短路径，代码实现为三层 for 循环，较为好理解
>
> - Dijkstra 用于求带权图（无负权值）的单源最短路径，也可用于求所有顶点间的最短路径，重复 |V| 次，时间复杂度为 O(n^3)

实例 + 图就能理解了，[见链接](https://zhuanlan.zhihu.com/p/536843618)

![](https://picx.zhimg.com/v2-fb27d36bdd03386263190d9ef245b529_1440w.jpg)

![](https://pica.zhimg.com/v2-8f93fce5a0242c3e86099e97e805c428_1440w.jpg)

![](https://pic1.zhimg.com/v2-69ea4f51d59fbd8db4216e02b3a0f0d8_1440w.jpg)

![](https://pica.zhimg.com/v2-404c5da505cca4ce2261d15d46ed28fe_1440w.jpg)

![](https://pic1.zhimg.com/v2-4dc53f4d0d4f19f20ad1019f748c9d80_1440w.jpg)





### 有向无环图（DAG图）的描述表达式

需要视频辅助，因为这个有做题技巧。

说起做题技巧，突然想到似乎看过前中序构建图的技巧视频？





### 拓扑排序

#### AOV 网

AOV 网(Activity On Vertex NetWork)：用**顶点**表示**活动**的网

用 DAG 图（有向无环图）表示一个工程。顶点表示活动，有向边 <Vi, Vj> 表示活动 Vi 必须先于活动 Vj 进行



#### 拓扑排序

拓扑排序定义一：

在图论中，由一个有向无环图的顶点组成的序列，当且仅当满足下列条件时，称为该图的一个拓扑排序：

- 每个顶点出现且只出现一次。
- 若顶点 A 在序列中排在顶点 B 的前面，则在图中不存在从顶点 B 到顶点 A 的路径。



**拓扑排序定义二：**

对有向无环图的顶点的一种排序，它使得若存在一条从顶点 A 到顶点 B 的路径，则在排序中顶点 B 出现在顶点 A 的后面。



拓扑排序的实现：

- 从 AOV 网中选择一个没有前驱（入度为0）的顶点并输出。
- 从网中删除该顶点和所有以它为起点的有向边。
- 重复前面的步骤直到当前的 AOV 网为空或当前网中不存在无前驱的顶点为止。

> [!IMPORTANT]
>
> - 时间复杂度：O(|V|+|E|)
> - 若采用邻接矩阵，则需O(|V|^2)



### 逆拓扑排序

对一个 AOV 网，如果采用下列步骤进行排序，则称之为逆拓扑排序：

- 从 AOV 网中选择一个没有后继（出度为0）的顶点并输出。
- 从网中删除该顶点和所有以它为终点的有向边。
- 重复上面步骤直到当前的 AOV 网为空。

可以使用逆邻接表和 DFS 实现



### 关键路径

#### AOE网

在带权有向图中，以**顶点**表示**事件**，以**有向边**表示活动，以边上的**权值**表示完成该活动的**开销**（如完成活动所需的时间），称之为用边表示活动的网络，简称 AOE 网 (Activity On Edge NetWork)

AOE 网具有以下两个性质：

- 只有在某顶点**所代表的事件发生后**，从该顶点出发的各有向边所代表的活动**才能开始**

- 只有在**进入某顶点的各有向边**所代表的活动**都已结束时**，该顶点所代表的事件**才能发生**。

  > 这个性质指的是，某个事件发生的前提是前置活动均已结束！前置活动是指该顶点的入度们的

特别地，AOE 网的有些活动是可以并行进行的。



![](https://pic1.zhimg.com/v2-3559b2da26ab2e9cc493f3993e920646_1440w.jpg)



#### 关键路径

#### 求关键路径的步骤

- 求所有事件的最早发生时间 ve( )

  由于 AOE 网的性质之一是：只有在**进入某顶点的各有向边**所代表的活动**都已结束时**，该顶点所代表的事件**才能发生**。因此，ve(k) = **Max**{ ve(k-1) + weight }（各个 前驱节点 ve + 对应边的权值 的集合中的最大值）

- 求所有事件的最迟发生时间 vl( )

  这个需要逆推，需要最后一个节点的最早发生时间！记为 v(n)
  那么 v(n-1) = **Min**{ v(n) - weight }（n 是 n-1 的任意后继，因为是求最迟发生时间，所以取 Min）

- 求所有活动的最早发生时间 e( )

  等于活动的弧头顶点的最早发生时间，即 e() **=** ve()

- 求所有活动的最迟发生时间 l( )

  l(k) = **Max**{ vl(k+1) - weight }（各个 后驱顶点的最迟发生时间 - 对应边权值 的集合中的最大值）

关键活动的定义：l = e（活动最早发生时间和最迟发生时间相等，即没有时间余量的活动为关键活动）



> 需要举个实例，不然不懂
>
> 可能的参考链接：
>
> - [链接一](https://blog.csdn.net/vavid317/article/details/116741759)




---

## 查找

### 分块查找

- 特点：块内无序、块间有序

> [!IMPORTANT]
>
> 由于分块查找的特点是块内无序、块间有序，这意味着块间可以使用针对有序序列的查找方法，而块内由于数量级较小，哪怕使用一般方法，总的时间消耗也不会太多。
>
> 分块查找可以联想桶排序：
> 以 double 元素序列的桶排序，首先将元素归一化到 [0, 1] 内，均分为 k 块，第一次遍历的时候，分流到各个桶中，然后对桶分别排序。
> 简单计算一下，元素为 n，桶中元素平均为 n/k，那么一个桶使用快速排序耗时 O(n/k * log n/k)，所有桶为 O(n * log n/k)，当 k 足够大的时候，时间复杂度趋近 O(n)。最好再加上合并的耗时，总耗时大概为 O(n+k)







---

## 排序

### 插入排序

> [!IMPORTANT]
>
> - 空间复杂度：O(1)
> - 时间复杂度：主要来自对比关键字、移动元素，若有 n 个元素，则需要 n-1 趟处理
>   - 最好时间复杂度：O(n) 共n-1趟处理，每一趟只需要对比关键字1次，不用移动元素
>   - 最坏时间复杂度：O(n^2) 共n-1趟处理，每一趟都需要从尾移到到头（全部逆序）



### 希尔排序

> [!IMPORTANT]
>
> - 空间复杂度：O(1)
> - 时间复杂度：
>   - 和增量序列 d1, d2, d3… 的选择有关，目前无法用数学手段证明确切的时间复杂度
>   - 最坏时间复杂度为 O(n^2)，当n在某个范围内时，可达O(n^1.3)
> - 稳定性：不稳定
> - 适用性：仅适用于顺序表，不适用于链表



王道的代码实现第一次阅读可能会有些困惑。**实际上，并没有那么复杂**，王道的代码实现的第二个 for 循环约等于遍历一遍整个序列，**第三个 for 循环就是将当前遍历到的元素插入到前面的增量序列中**！

之所以说第一次阅读的时候可能有些困惑，是因为希尔排序可以分解成如下操作：
根据 d 这个增量值，**提取出来大概 d 个序列，排序之后，再合并。**
上述实现更好理解，但是和王道的代码实现不一样，这才是困惑的原因！

  

### 冒泡排序

> [!IMPORTANT]
>
> - 空间复杂度：O(1)
> - 时间复杂度：
>   - 最好情况（有序）：O(n)
>   - 最坏情况（逆序）：O(n^2)
>   - 平均情况：O(n^2)
>
> - 稳定性：稳定
> - 适用性：顺序表、链表都可以（因为是相邻交换）



### 快速排序





### 堆排序

在顺序存储的完全二叉树中，非终端结点编号 i≤⌊n/2⌋，由于堆调整只需要从非终端结点开始调整，因此需要用到这个计算。



### 归并排序





### 基数排序

**简单例子**，三位数十进制整数排序，r = 10，d = 3（r  为进制，d 为位数）

第一轮，个位分配，然后收集，得到中间结果队列

第二轮，十位分配，然后收集，得到中间结果队列

第三轮，百位分配，然后收集，得到最终结果队列

对上述进行时间复杂度分析，每轮分配耗时 O(n)，收集耗时 O(r)，共 d 轮，得到总耗时为 O(d*(n + r))



> [!CAUTION]
>
> 上面关于基数排序的例子较为简单，实际基数排序的应用比较考验分析能力，即你到底能不能确定这可以使用基数排序....



> [!NOTE]
>
> 基数排序是不基于比较的排序，所以时间复杂度和 O(n) 接近一个量级
>
> 基数排序擅长解决的问题：
>
> - 数据元素的关键字可以方便地拆分为 d 组，且 d 较小
> - 每组关键字的取值范围不大，即 r 较小
> - 数据元素个数 n 较大
>
> 比如：
>
> - 某学校有 10000 名学生，将学生信息按照年龄递减排序
>
>   出生日期大概形如 20010101，那么对出生日期排序即可
>
>   此处甚至可以分三次排：
>
>   - 年：r = 3000, d = 1,  n = 10000
>   - 月：r = 12, d = 1, n = 10000
>   - 日：r = 31, d = 1, n = 10000
>
>   最后求和
>
> - 给十亿人的身份证号排序
>
>   r = 10, d = 18, n = 10^9



### 外部排序





### 败者树

#### 败者树的基本概念

- 用途：用于从 k 个序列中选择最小（或最大）元素
- 特点：
  - 败者树是一颗完全二叉树
  - 每个非叶子节点存储的是败者（原因：k 中的 1 个胜者选出后，新入列的元素可以和败者继续比较）



#### 败者树的结构

- 叶子节点：其实可以是虚构的，k 路归并的败者树其实只需要长度为 k 的数组，如果算上这个虚构节点，则是 长度为 2*k 的数组，该数组是完全二叉树的物理存储结构（2\*i 和 2\*i + 1，i > 0）
- 非终端节点：存储比较中的败者
- 根节点：存储最终的胜者（注意，这个根节点是一般 k 叉树的根节点多了一个头头）



#### 败者树的优点

- 适合外部排序，用于从多个有序队列中找到最小（或最大）的元素。即败者树可以搞笑地合并多个有序序列
- 高效：每次调整败者树的时间复杂度为 O(logk)，适合处理大规模数据



> [!CAUTION]
>
> 此处的内容均是简单理解，可能不完全对













## 感悟

1. excalidraw + processon + ppt 要学会搭配使用！

2. mermaid 值得学习！

   - [Mermaid 官方文档](http://mermaid.js.org/)
   - [在线编辑器](https://mermaid.live/)
   - [Mermaid 源码和 Issue](https://github.com/mermaid-js/mermaid)

3. 这种相对详细的笔记博客阅读一遍，之后再去系统学习，似乎是个比较好的学习方法。

   优点如下：

   - 快速入门，能尽早收获正反馈
   - 学习过程中遇到暂时实在不懂的可以跳过，系统学习的时候深入
   - 重复学习，可以加深印象，更不易遗忘

4. 



## 待巩固

1. 卡特兰（Catalan）数
2. 判断队列已满/已空
3. 栈在表达式求值中的应用，如：中缀表达式转后缀表达式。栈在递归中的应用，如：函数调用的特点。
4. 特殊矩阵的压缩储存，如：对称矩阵、三角矩阵、三对角矩阵/带状矩阵、**稀疏矩阵**
5. 二叉树性质
6. 并查集的压缩路径
7. 拓扑排序和逆拓扑排序
8. 如何求关键路径（四个队列），找个题目练习
9. 堆排序时间复杂度分析/关键字对比次数分析
10. 外部排序的时间开销分析和优化思路
11. 

## 待办

1. 朴素模式匹配算法和 **KMP 算法**
2. 十字链表、邻接多重表
3. 有向无环图（DAG图）的描述表达式（这个推荐看一下视频，有记忆技巧的）
4. **B 树、B+ 树**
5. 置换-选择排序
6. 最佳归并树



在全部过一遍后，请重新过一遍目录，判断一下哪些知识漏了
